import os
import requests
import datetime
import random
import json

# ================= é…ç½®åŒº =================
# è‡ªåŠ¨å®šä½åˆ° source/_posts ç›®å½•
script_dir = os.path.dirname(os.path.abspath(__file__))
POSTS_DIR = os.path.join(script_dir, '..', 'source', '_posts')

# ç¯å¢ƒå˜é‡è·å–
API_KEY = os.environ.get("LLM_API_KEY")
BASE_URL = os.environ.get("LLM_BASE_URL", "https://api.deepseek.com")


# =========================================

def get_daily_quote():
    """
    ã€çœŸå®å…¬å¼€æºã€‘è·å–é‡‘å±±è¯éœ¸æ¯æ—¥ä¸€å¥
    è¿”å›: (è‹±æ–‡å¥å­, ä¸­æ–‡ç¿»è¯‘, å›¾ç‰‡URL)
    """
    try:
        url = "http://open.iciba.com/dsapi/"
        res = requests.get(url, timeout=5).json()
        return res['content'], res['note'], res['picture2']
    except:
        return "Stay hungry, stay foolish.", "æ±‚çŸ¥è‹¥é¥¥ï¼Œè™šå¿ƒè‹¥æ„šã€‚", "https://images.unsplash.com/photo-1499209974431-9dddcece7f88?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80"


def generate_learning_content():
    """
    ã€AI ç”Ÿæˆã€‘è°ƒç”¨ LLM ç”Ÿæˆå•è¯è¡¨å’Œé•¿æ–‡é˜…è¯»
    """
    if API_KEY:
        print(f"DEBUG: API Key found (starts with {API_KEY[:3]}...)")
    else:
        print("Error: LLM_API_KEY is missing.")
        return None

    # å®šä¹‰å¤šå…ƒåŒ–çš„é˜…è¯»ä¸»é¢˜æ± 
    topics = [
        "TED Talk (Inspirational & Educational)",
        "Cognitive Psychology & Mental Health",  # å¿ƒç†
        "Optics & Metasurfaces Technology",  # å…‰å­¦/è¶…è¡¨é¢ (ä½ çš„ä¸“ä¸š)
        "Nature & Wildlife Documentary",  # è‡ªç„¶
        "Global Travel & Cultural Exploration",  # æ—…æ¸¸
        "Personal Growth & Career Development"  # æˆé•¿
    ]
    today_topic = random.choice(topics)
    print(f"Today's Topic: {today_topic}")

    # ğŸŸ¢ System Prompt
    system_prompt = "You are a professional ESL (English as a Second Language) teacher and editor. Your goal is to provide high-quality reading materials and vocabulary lists for advanced learners."

    # ğŸŸ¢ User Prompt (é«˜è¦æ±‚)
    user_prompt = f"""
    Please generate a comprehensive daily English learning post based on the topic: **{today_topic}**.

    **REQUIREMENTS:**

    1. **Part 1: Vocabulary Builder (10 Words)**
       - Select exactly **10 sophisticated/useful words** related to the topic.
       - For each word, provide:
         - Word
         - IPA Pronunciation
         - **English Definition**
         - **Chinese Definition** (Keep it concise)
         - A Sample Sentence showing proper usage.

    2. **Part 2: Deep Reading Article**
       - Title: Create an engaging title based on {today_topic}.
       - Length: **Long-form article (approx. 200-500 words)**. Do not write a short summary; write a full article.
       - Style: Professional, informative, and engaging (like The Economist or NatGeo).
       - **Analysis**: At the end, explain 3 complex sentence structures or idioms used in the text.

    **OUTPUT FORMAT (Strict JSON):**
    {{
        "topic_display": "{today_topic}",
        "vocab_list": [
            {{ "word": "...", "ipa": "...", "en_def": "...", "cn_def": "...", "sentence": "..." }},
            ... (total 10 items)
        ],
        "reading": {{
            "title": "...",
            "content": "...", 
            "analysis": "..."
        }}
    }}
    """

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "response_format": {"type": "json_object"}
    }

    try:
        print("Requesting AI generation (this may take 30-60s due to long content)...")
        response = requests.post(f"{BASE_URL}/chat/completions", headers=headers, json=data, timeout=90)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°90ç§’
        result = response.json()
        content_json = json.loads(result['choices'][0]['message']['content'])
        return content_json
    except Exception as e:
        print(f"AI Generation Failed: {e}")
        return None


def create_markdown():
    now = datetime.datetime.now()
    date_str = now.strftime("%Y-%m-%d")

    # 1. å¹¶è¡Œè·å–ï¼šé‡‘å±±è¯éœ¸å¥ + AIç”Ÿæˆå†…å®¹
    quote_en, quote_cn, quote_img = get_daily_quote()
    ai_data = generate_learning_content()

    if not ai_data:
        print("Skipping generation due to AI failure.")
        return

    # æå– AI æ•°æ®
    topic = ai_data['topic_display']
    vocabs = ai_data['vocab_list']
    reading = ai_data['reading']

    # 2. æ„å»ºå•è¯è¡¨ Markdown (10ä¸ª)
    vocab_md = ""
    for v in vocabs:
        vocab_md += f"""
- **{v['word']}** `/{v['ipa']}/`
  - ğŸ‡ºğŸ‡¸ {v['en_def']}
  - ğŸ‡¨ğŸ‡³ {v['cn_def']}
  - ğŸ“ *{v['sentence']}*
"""

    # 3. æ„å»ºæ•´ç¯‡ Markdown
    md_content = f"""---
title: "ğŸŒ Daily English: {reading['title']} | {date_str}"
date: {now.strftime("%Y-%m-%d %H:%M:%S")}
categories: English Learning
tags: [English, {topic}, Vocabulary, Reading]
---

## ğŸ–¼ï¸ Part 1: Daily Quote

![]({quote_img})

> **"{quote_en}"**
>
> {quote_cn}

---

## ğŸ”‘ Part 2: Vocabulary Builder (10 Words)

Here are 10 key words selected from today's reading on **{topic}**:

{vocab_md}

---

## ğŸ“– Part 3: Deep Reading

### {reading['title']}

{reading['content']}

---

### ğŸ’¡ Language Highlights

{reading['analysis']}

---

*(Content generated by DeepSeek AI; Quote source: Iciba)*
"""

    # 4. å†™å…¥æ–‡ä»¶
    # æ–‡ä»¶åæ ¼å¼: 2025-01-01-daily-english.md
    filename = f"{date_str}-daily-english.md"
    filepath = os.path.join(POSTS_DIR, filename)

    # âš ï¸ è°ƒè¯•æ¨¡å¼ï¼šå¼ºåˆ¶è¦†ç›–å†™å…¥ï¼Œæ–¹ä¾¿ä½ åå¤æµ‹è¯•æ•ˆæœ
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(md_content)
    print(f"Successfully generated (Overwritten): {filename}")


if __name__ == "__main__":
    create_markdown()